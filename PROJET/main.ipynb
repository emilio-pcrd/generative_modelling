{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Learning Gradients of Convex Functions with monotone Gradient networks**\n",
    "\n",
    "Thomas Gravier, Emilio Picard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 7\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.cuda.manual_seed(SEED)  # only if cuda is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Toy Example of the paper**\n",
    "The purpose here is to approximate the gradient of a convex function $f$.\n",
    "\n",
    "Let $f$ be $f(x) = x_1^4 + \\frac{x_2}{2} + \\frac{x_1x_2}{2} + \\frac{3x_2^2}{2} - \\frac{x_2^3}{3}$, where $x = [x_1, x_2]^T$.\n",
    "\n",
    "We want to approximate $\\nabla f(x) = [4x_1^3 + \\frac{x_2}{2}, \\frac{1}{2}+ \\frac{x_1}{2} + 3x_2 - x_2^2]$ with several methods of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x1, x2):\n",
    "    return x1**4 + (x2**2)/2 + (x1*x2)/2 + 3*(x2**2)/2 - (x2**3)/3\n",
    "\n",
    "def grad_f(z): \n",
    "    x1 = z[:, 0]\n",
    "    x2 = z[:, 1]\n",
    "    return torch.stack([4*x1**3 + x2/2, 1/2 + x1/2 + 3*x2 - x2**2]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHAT WE WANT TO APPROXIMATE\n",
    "\n",
    "x = torch.linspace(0, 1, 15)\n",
    "y = torch.linspace(0, 1, 15)\n",
    "\n",
    "X, Y = torch.meshgrid(x, y)\n",
    "space = torch.cat([torch.reshape(X,(-1,1)),torch.reshape(Y,(-1,1))],1)\n",
    "grad = grad_f(space)\n",
    "\n",
    "cmap = 'plasma'\n",
    "levels = 30\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4), dpi=300)\n",
    "\n",
    "contour = axs[0].contourf(x, y, f(space[:,0], space[:,1]).view(x.numel(),x.numel()).T, levels=levels, cmap=cmap)\n",
    "axs[0].set_xticks([0, 0.5, 1.0])\n",
    "axs[0].set_yticks([0, 0.5, 1.0])\n",
    "axs[0].tick_params(axis='both', length=20, which='major')\n",
    "cbar = fig.colorbar(contour, ax=axs[0])\n",
    "cbar.set_label('Function Value')\n",
    "cbar.ax.tick_params()\n",
    "\n",
    "quiver = axs[1].quiver(space[:,0], space[:,1], grad[:,0], grad[:,1], grad.norm(dim=-1), cmap=cmap)\n",
    "axs[1].set_xticks([0, 0.5, 1.0])\n",
    "axs[1].set_yticks([0, 0.5, 1.0])\n",
    "axs[1].tick_params(axis='both', length=20, which='major')\n",
    "cbar = fig.colorbar(quiver, ax=axs[1])\n",
    "cbar.set_label('Gradient Norm')\n",
    "cbar.ax.tick_params()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "from models import CascadeGradNet, ModularGradNet\n",
    "\n",
    "# get data: sample points from the unit square\n",
    "sampled_points = torch.rand((1000000, 2))\n",
    "\n",
    "DATASET = TensorDataset(sampled_points, grad_f(sampled_points))\n",
    "split = int(0.8 * len(DATASET))\n",
    "TRAIN_SET, VAL_SET = random_split(DATASET, [split, len(DATASET) - split])\n",
    "TRAIN_LOADER = DataLoader(TRAIN_SET, batch_size=5000, shuffle=True)\n",
    "VAL_LOADER = DataLoader(VAL_SET, batch_size=5000, shuffle=False)\n",
    "\n",
    "NUM_LAYERS, NUM_MODULES = 3, 3\n",
    "IN_DIM = 2\n",
    "EMBED_DIM = 8\n",
    "ACTIVATTION = lambda : nn.Tanh()\n",
    "\n",
    "# CascadeGradNet\n",
    "model1 = CascadeGradNet(\n",
    "    num_layers=NUM_LAYERS,\n",
    "    in_dim=IN_DIM,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    activation=ACTIVATTION\n",
    ").to(DEVICE)\n",
    "print(f\"number of learnable parameters: {sum(p.size().numel() for p in model1.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Train the Gradients Networks for the toy example of the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, val_loader, grad_f, model_name):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    global DEVICE, NUM_EPOCHS\n",
    "\n",
    "    model.to(DEVICE)\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = 1\n",
    "    for epoch in tqdm(range(NUM_EPOCHS), desc=f\"Training\"):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, grads in train_loader:\n",
    "            x, grads = x.to(DEVICE), grads.to(DEVICE)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, grads)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, grads in val_loader:\n",
    "                x, grads = x.to(DEVICE), grads.to(DEVICE)\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, grads)\n",
    "                val_loss += loss.item()\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f\"{model_name}.pt\")\n",
    "\n",
    "        if epoch+1 % 100 == 0:\n",
    "            print(\"Epoch: \", epoch, \"Train Loss: \", train_loss / len(train_loader), \"Val Loss: \", val_loss / len(val_loader))\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "print(\"Training CascadeGradNet\")\n",
    "print(\"device used: \", DEVICE)\n",
    "train_losses_C, val_losses_C = train_model(\n",
    "        model1,\n",
    "        train_loader=TRAIN_LOADER,\n",
    "        val_loader=VAL_LOADER,\n",
    "        grad_f=grad_f,\n",
    "        model_name='CascadeGradNet'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l2_error_map(model, space, grad_f):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        true_grads = grad_f(space).to(DEVICE)\n",
    "        predicted_grads = model(space.to(DEVICE))\n",
    "        l2_error = F.mse_loss(predicted_grads, true_grads, reduction='none').sum(dim=1).cpu()\n",
    "    return l2_error\n",
    "\n",
    "l2_error_map_C = compute_l2_error_map(model1, space, grad_f)\n",
    "l2_error_map_C = l2_error_map_C.view(x.numel(), y.numel()).T\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3), dpi=300)\n",
    "contour = ax.contourf(x, y, l2_error_map_C, levels=levels, cmap=cmap)\n",
    "ax.set_xticks([0, 0.5, 1.0])\n",
    "ax.set_yticks([0, 0.5, 1.0])\n",
    "ax.tick_params(axis='both', length=10)\n",
    "cbar = fig.colorbar(contour, ax=ax)\n",
    "cbar.set_label('L2 Error')\n",
    "cbar.ax.tick_params()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_grad = model1(space.to(DEVICE)).detach().cpu()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4), dpi=300)\n",
    "\n",
    "quiver_true = axs[0].quiver(space[:,0], space[:,1], grad[:,0], grad[:,1], grad.norm(dim=-1), cmap=cmap)\n",
    "axs[0].set_title('True Gradients')\n",
    "axs[0].set_xticks([0, 0.5, 1.0])\n",
    "axs[0].set_yticks([0, 0.5, 1.0])\n",
    "axs[0].tick_params(axis='both', length=20, which='major')\n",
    "cbar_true = fig.colorbar(quiver_true, ax=axs[0])\n",
    "cbar_true.set_label('Gradient Norm')\n",
    "cbar_true.ax.tick_params()\n",
    "\n",
    "quiver_pred = axs[1].quiver(space[:,0].cpu().numpy(), space[:,1].cpu().numpy(), predicted_grad[:,0].numpy(), predicted_grad[:,1].numpy(), predicted_grad.norm(dim=-1).numpy(), cmap=cmap)\n",
    "axs[1].set_title('Predicted Gradients')\n",
    "axs[1].set_xticks([0, 0.5, 1.0])\n",
    "axs[1].set_yticks([0, 0.5, 1.0])\n",
    "axs[1].tick_params(axis='both', length=20, which='major')\n",
    "cbar_pred = fig.colorbar(quiver_pred, ax=axs[1])\n",
    "cbar_pred.set_label('Gradient Norm')\n",
    "cbar_pred.ax.tick_params()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example 2 for another convex function:\n",
    "\n",
    "$h(x) = \\log(\\exp(5x_1) + \\exp(2x_2))$\n",
    "\n",
    "$J_h(x) = [\\frac{5\\exp(5x_1)}{\\exp(5x_1) + \\exp(2x_2)}, \\frac{2\\exp(2x_2)}{\\exp(5x_1) + \\exp(2x_2)}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x1, x2):\n",
    "    return torch.log(torch.exp(5 * x1) + torch.exp(2 * x2))\n",
    "\n",
    "def grad_h(z): \n",
    "    x1 = z[:, 0]\n",
    "    x2 = z[:, 1]\n",
    "    return torch.stack([(5 * torch.exp(5 * x1)) / (torch.exp(5 * x1) + torch.exp(2 * x2)), \n",
    "                        (2 * torch.exp(2 * x2)) / (torch.exp(5 * x1) + torch.exp(2 * x2))]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHAT WE WANT TO APPROXIMATE\n",
    "\n",
    "x = torch.linspace(0, 1, 15)\n",
    "y = torch.linspace(0, 1, 15)\n",
    "\n",
    "X, Y = torch.meshgrid(x, y)\n",
    "space = torch.cat([torch.reshape(X,(-1,1)),torch.reshape(Y,(-1,1))],1)\n",
    "grad = grad_h(space)\n",
    "\n",
    "cmap = 'plasma'\n",
    "levels = 30\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4), dpi=300)\n",
    "\n",
    "contour = axs[0].contourf(x, y, h(space[:,0], space[:,1]).view(x.numel(),x.numel()).T, levels=levels, cmap=cmap)\n",
    "axs[0].set_xticks([0, 0.5, 1.0])\n",
    "axs[0].set_yticks([0, 0.5, 1.0])\n",
    "axs[0].tick_params(axis='both', length=20, which='major')\n",
    "cbar = fig.colorbar(contour, ax=axs[0])\n",
    "cbar.set_label('Function Value')\n",
    "cbar.ax.tick_params()\n",
    "\n",
    "quiver = axs[1].quiver(space[:,0], space[:,1], grad[:,0], grad[:,1], grad.norm(dim=-1), cmap=cmap)\n",
    "axs[1].set_xticks([0, 0.5, 1.0])\n",
    "axs[1].set_yticks([0, 0.5, 1.0])\n",
    "axs[1].tick_params(axis='both', length=20, which='major')\n",
    "cbar = fig.colorbar(quiver, ax=axs[1])\n",
    "cbar.set_label('Gradient Norm')\n",
    "cbar.ax.tick_params()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModularGradNet\n",
    "model2 = ModularGradNet(\n",
    "    num_modules=NUM_MODULES,\n",
    "    in_dim=IN_DIM,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    activation=ACTIVATTION\n",
    ").to(DEVICE)\n",
    "print(f\"number of learnable parameters: {sum(p.size().numel() for p in model2.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "print(\"Training ModularGradNet\")\n",
    "print(\"device used: \", DEVICE)\n",
    "train_losses_C, val_losses_C = train_model(\n",
    "        model2,\n",
    "        train_loader=TRAIN_LOADER,\n",
    "        val_loader=VAL_LOADER,\n",
    "        grad_f=grad_f,\n",
    "        model_name='ModularGradNet'\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_map_M = compute_l2_error_map(model2, space, grad_h)\n",
    "l2_error_map_M = l2_error_map_C.view(x.numel(), y.numel()).T\n",
    "\n",
    "# Plot the L2-error map\n",
    "fig, ax = plt.subplots(figsize=(6, 3), dpi=300)\n",
    "contour = ax.contourf(x, y, l2_error_map_M, levels=levels, cmap=cmap)\n",
    "ax.set_xticks([0, 0.5, 1.0])\n",
    "ax.set_yticks([0, 0.5, 1.0])\n",
    "ax.tick_params(axis='both', length=10)\n",
    "cbar = fig.colorbar(contour, ax=ax)\n",
    "cbar.set_label('L2 Error')\n",
    "cbar.ax.tick_params()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_grad = model2(space.to(DEVICE)).detach().cpu()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4), dpi=300)\n",
    "\n",
    "quiver_true = axs[0].quiver(space[:,0], space[:,1], grad[:,0], grad[:,1], grad.norm(dim=-1), cmap=cmap)\n",
    "axs[0].set_title('True Gradients')\n",
    "axs[0].set_xticks([0, 0.5, 1.0])\n",
    "axs[0].set_yticks([0, 0.5, 1.0])\n",
    "axs[0].tick_params(axis='both', length=20, which='major')\n",
    "cbar_true = fig.colorbar(quiver_true, ax=axs[0])\n",
    "cbar_true.set_label('Gradient Norm')\n",
    "cbar_true.ax.tick_params()\n",
    "\n",
    "quiver_pred = axs[1].quiver(space[:,0].cpu().numpy(), space[:,1].cpu().numpy(), predicted_grad[:,0].numpy(), predicted_grad[:,1].numpy(), predicted_grad.norm(dim=-1).numpy(), cmap=cmap)\n",
    "axs[1].set_title('Predicted Gradients')\n",
    "axs[1].set_xticks([0, 0.5, 1.0])\n",
    "axs[1].set_yticks([0, 0.5, 1.0])\n",
    "axs[1].tick_params(axis='both', length=20, which='major')\n",
    "cbar_pred = fig.colorbar(quiver_pred, ax=axs[1])\n",
    "cbar_pred.set_label('Gradient Norm')\n",
    "cbar_pred.ax.tick_params()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train for transport of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, CRITERION, NUM_EPOCHS, DEVICE, model_name='model'):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in tqdm(range(NUM_EPOCHS), desc=f\"Training {model_name}\"):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            outputs = model(x)\n",
    "            loss = CRITERION(outputs, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "                outputs = model(x)\n",
    "                loss = CRITERION(outputs, y)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f\"{model_name}.pt\")\n",
    "\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Train Loss: {train_losses[-1]:.6f} - Val Loss: {val_losses[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transport Distributions: from Gaussian to Banana Shape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "b = 1\n",
    "c = 0.5\n",
    "\n",
    "X_torch = torch.randn(n_samples)\n",
    "Y_torch = torch.randn(n_samples)\n",
    "\n",
    "Y_banana_torch = Y_torch + b * (X_torch**2 - c)\n",
    "theta_torch = torch.tensor(np.pi / 5, dtype=torch.float32, device=X_torch.device)\n",
    "rotation_matrix_torch = torch.tensor([\n",
    "    [torch.cos(theta_torch), -torch.sin(theta_torch)],\n",
    "    [torch.sin(theta_torch), torch.cos(theta_torch)]\n",
    "], dtype=torch.float32, device=X_torch.device)\n",
    "\n",
    "points_torch = torch.stack((X_torch, Y_banana_torch))\n",
    "rotated_points_torch = torch.matmul(rotation_matrix_torch, points_torch)\n",
    "X_rotated_torch, Y_rotated_torch = rotated_points_torch.cpu().numpy()\n",
    "\n",
    "# Distribution gaussienne\n",
    "mu = np.array([-6, 4])\n",
    "cov = np.array([[1, 0], [0, 1]])\n",
    "data2 = np.random.multivariate_normal(mu, cov, n_samples)\n",
    "X_gaussian_torch = torch.tensor(data2[:, 0], dtype=torch.float32, device=X_torch.device)\n",
    "Y_gaussian_torch = torch.tensor(data2[:, 1], dtype=torch.float32, device=X_torch.device)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_gaussian_torch, Y_gaussian_torch, alpha=0.5, s=10, color='red')\n",
    "plt.scatter(X_rotated_torch, Y_rotated_torch, alpha=0.5, s=10, color='blue')\n",
    "plt.title(\"Prior and expected posterior distributions\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.axvline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show(block=True)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_data_gaussian = torch.tensor(data2, dtype=torch.float32)\n",
    "tensor_data_banana = rotated_points_torch.T\n",
    "\n",
    "train_dataset = TensorDataset(tensor_data_gaussian[:1600], tensor_data_banana[:1600])\n",
    "val_dataset = TensorDataset(tensor_data_gaussian[1600:], tensor_data_banana[1600:])\n",
    "num_workers = min(4, os.cpu_count())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CascadeGradNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geomloss import SamplesLoss\n",
    "CRITERION = SamplesLoss(\"sinkhorn\", p=2, blur=0.05, backend=\"tensorized\")\n",
    "\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "NUM_LAYERS = 6\n",
    "IN_DIM = 2\n",
    "EMBED_DIM = 16\n",
    "ACTIVATION = lambda : nn.Tanh()\n",
    "\n",
    "model1 = CascadeGradNet(\n",
    "    num_layers=NUM_LAYERS,\n",
    "    in_dim=IN_DIM,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    activation=ACTIVATION\n",
    ").to(DEVICE)\n",
    "\n",
    "train_model(model1, train_loader, val_loader, CRITERION, NUM_EPOCHS, DEVICE, model_name='CascadeGradNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load_state_dict(torch.load(\"CascadeGradNetBanana.pt\"))\n",
    "model1.eval()\n",
    "\n",
    "source_samples = tensor_data_gaussian[:1000].to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    transported_samples = model1(source_samples).cpu().numpy()\n",
    "\n",
    "source_samples = source_samples.cpu().numpy()\n",
    "target_samples = tensor_data_banana[:1000].cpu().numpy()\n",
    "\n",
    "sampling_rate = 0.2\n",
    "num_points = len(source_samples)\n",
    "num_sampled = max(1, int(sampling_rate * num_points))\n",
    "\n",
    "sampled_indices = np.random.choice(num_points, num_sampled, replace=False)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i in sampled_indices:\n",
    "    plt.plot([source_samples[i, 0], transported_samples[i, 0]], \n",
    "             [source_samples[i, 1], transported_samples[i, 1]], \n",
    "             color='gray', alpha=0.5, linewidth=0.8)\n",
    "\n",
    "plt.scatter(source_samples[:, 0], source_samples[:, 1], alpha=0.6, s=10, color='blue', label='Source (Gaussienne)')\n",
    "plt.scatter(transported_samples[:, 0], transported_samples[:, 1], alpha=0.6, s=10, color='red', label='Transported')\n",
    "plt.scatter(target_samples[:, 0], target_samples[:, 1], alpha=0.6, s=10, color='green', label='Target (Banane)')\n",
    "plt.title(\"Transport de la Gaussienne vers les points transportés (20% des points)\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.axvline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "wd_x = wasserstein_distance(transported_samples[:, 0], target_samples[:, 0])\n",
    "wd_y = wasserstein_distance(transported_samples[:, 1], target_samples[:, 1])\n",
    "\n",
    "wasserstein_dist = (wd_x + wd_y) / 2\n",
    "wasserstein_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M-MGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geomloss import SamplesLoss\n",
    "CRITERION = SamplesLoss(\"sinkhorn\", p=2, blur=0.05, backend=\"tensorized\")\n",
    "\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "NUM_MODULES = 6\n",
    "IN_DIM = 2\n",
    "EMBED_DIM = 16\n",
    "ACTIVATION = lambda : nn.Tanh()\n",
    "\n",
    "model1 = ModularGradNet(\n",
    "    num_modules=NUM_BLOCKS,\n",
    "    in_dim=IN_DIM,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    activation=ACTIVATION\n",
    ").to(DEVICE)\n",
    "\n",
    "train_model(model1, train_loader, val_loader, CRITERION, NUM_EPOCHS, DEVICE, model_name='M-GradNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load_state_dict(torch.load(\"M-GradNetBanana.pt\"))\n",
    "model1.eval()\n",
    "\n",
    "source_samples = tensor_data_gaussian[:1000].to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    transported_samples = model1(source_samples).cpu().numpy()\n",
    "\n",
    "source_samples = source_samples.cpu().numpy()\n",
    "target_samples = tensor_data_banana[:1000].cpu().numpy()\n",
    "\n",
    "sampling_rate = 0.2\n",
    "num_points = len(source_samples)\n",
    "num_sampled = max(1, int(sampling_rate * num_points))\n",
    "\n",
    "sampled_indices = np.random.choice(num_points, num_sampled, replace=False)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for i in sampled_indices:\n",
    "    plt.plot([source_samples[i, 0], transported_samples[i, 0]], \n",
    "             [source_samples[i, 1], transported_samples[i, 1]], \n",
    "             color='gray', alpha=0.5, linewidth=0.8)\n",
    "\n",
    "plt.scatter(source_samples[:, 0], source_samples[:, 1], alpha=0.6, s=10, color='blue', label='Source (Gaussienne)')\n",
    "plt.scatter(transported_samples[:, 0], transported_samples[:, 1], alpha=0.6, s=10, color='red', label='Transported')\n",
    "plt.scatter(target_samples[:, 0], target_samples[:, 1], alpha=0.6, s=10, color='green', label='Target (Banane)')\n",
    "\n",
    "plt.title(\"Distribution transport from a Gaussian to a Banana-shaped distribution\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.axvline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.savefig(\"M-GradNet_Transport.pdf\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "wd_x = wasserstein_distance(transported_samples[:, 0], target_samples[:, 0])\n",
    "wd_y = wasserstein_distance(transported_samples[:, 1], target_samples[:, 1])\n",
    "asserstein_dist = (wd_x + wd_y) / 2\n",
    "wasserstein_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transport Distributions: from Gaussian to another Gaussian**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "\n",
    "mu1 = np.array([-6, 4])\n",
    "cov1 = np.array([[1, 0], [0, 1]])\n",
    "data_gaussian1 = np.random.multivariate_normal(mu1, cov1, n_samples)\n",
    "X_gaussian1 = data_gaussian1[:, 0]\n",
    "Y_gaussian1 = data_gaussian1[:, 1]\n",
    "\n",
    "mu2 = np.array([2, -3])\n",
    "cov2 = np.array([[1, 0.5], [0.5, 1]])\n",
    "data_gaussian2 = np.random.multivariate_normal(mu2, cov2, n_samples)\n",
    "X_gaussian2 = data_gaussian2[:, 0]\n",
    "Y_gaussian2 = data_gaussian2[:, 1]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_gaussian1, Y_gaussian1, alpha=0.5, s=10, color='red', label='Gaussian 1')\n",
    "plt.scatter(X_gaussian2, Y_gaussian2, alpha=0.5, s=10, color='green', label='Gaussian 2')\n",
    "plt.title(\"Prior and expected posterior distributions\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.axvline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_data_gaussian1 = torch.tensor(data_gaussian1, dtype=torch.float32)\n",
    "tensor_data_gaussian2 = torch.tensor(data_gaussian2, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(tensor_data_gaussian1[:1600], tensor_data_gaussian2[:1600])\n",
    "val_dataset = TensorDataset(tensor_data_gaussian1[1600:], tensor_data_gaussian2[1600:])\n",
    "num_workers = min(4, os.cpu_count())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CascadeGradNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geomloss import SamplesLoss\n",
    "CRITERION = SamplesLoss(\"sinkhorn\", p=2, blur=0.05, backend=\"tensorized\")\n",
    "\n",
    "NUM_EPOCHS = 500\n",
    "\n",
    "NUM_LAYERS = 3\n",
    "IN_DIM = 2\n",
    "EMBED_DIM = 8\n",
    "ACTIVATION = lambda : nn.Tanh()\n",
    "\n",
    "model1 = CascadeGradNet(\n",
    "    num_layers=NUM_LAYERS,\n",
    "    in_dim=IN_DIM,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    activation=ACTIVATION\n",
    ").to(DEVICE)\n",
    "\n",
    "train_model(model1, train_loader, val_loader, CRITERION, NUM_EPOCHS, DEVICE, model_name='CascadeGradNetGaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model1.load_state_dict(torch.load(\"CascadeGradNetGaussian.pt\"))\n",
    "model1.eval()\n",
    "\n",
    "source_samples = tensor_data_gaussian1[:1000].to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    transported_samples = model1(source_samples).cpu().numpy()\n",
    "\n",
    "source_samples = source_samples.cpu().numpy()\n",
    "target_samples = tensor_data_gaussian2[:1000].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 0.2\n",
    "num_points = len(source_samples)\n",
    "num_sampled = max(1, int(sampling_rate * num_points))\n",
    "sampled_indices = np.random.choice(num_points, num_sampled, replace=False)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for i in sampled_indices:\n",
    "    plt.plot([source_samples[i, 0], transported_samples[i, 0]], \n",
    "             [source_samples[i, 1], transported_samples[i, 1]], \n",
    "             color='gray', alpha=0.5, linewidth=0.8)\n",
    "\n",
    "plt.scatter(source_samples[:, 0], source_samples[:, 1], alpha=0.6, s=10, color='blue', label='Source')\n",
    "plt.scatter(transported_samples[:, 0], transported_samples[:, 1], alpha=0.6, s=10, color='red', label='Transported')\n",
    "plt.scatter(target_samples[:, 0], target_samples[:, 1], alpha=0.6, s=10, color='green', label='Target')\n",
    "plt.title(\"Distribution transport between Gaussians\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.axvline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.savefig(\"transport_gaussian012.pdf\",dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "wd_x = wasserstein_distance(transported_samples[:, 0], target_samples[:, 0])\n",
    "wd_y = wasserstein_distance(transported_samples[:, 1], target_samples[:, 1])\n",
    "\n",
    "wasserstein_dist = (wd_x + wd_y) / 2\n",
    "wasserstein_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Model - Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = model(X_data).detach().cpu().numpy()\n",
    "Y_original = Y_data.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wasserstein_distances = [\n",
    "    wasserstein_distance(X_transformed[:, i], Y_original[:, i])\n",
    "    for i in range(X_transformed.shape[1])\n",
    "]\n",
    "wasserstein_score = np.mean(wasserstein_distances)\n",
    "print(f\"Distance de Wasserstein moyenne entre les distributions des '1' transformés et des '7' : {wasserstein_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Transport digit from 1 to 2, 2 to 3, etc.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meme chose avec M-MGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from geomloss import SamplesLoss\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "\n",
    "def init_W(embed_dim, in_dim):\n",
    "    return torch.randn(embed_dim, in_dim) * 0.01\n",
    "\n",
    "def init_b(size):\n",
    "    return torch.zeros(size)\n",
    "\n",
    "# ----- Modèle ModularGradNet -----\n",
    "class Module_ModularGN(nn.Module):\n",
    "    def __init__(self, in_dim, embed_dim, activation):\n",
    "        super().__init__()\n",
    "        self.beta = nn.Parameter(torch.rand(1), requires_grad=True)\n",
    "        self.W = nn.Parameter(init_W(embed_dim, in_dim), requires_grad=True)\n",
    "        self.b = nn.Parameter(init_b(embed_dim), requires_grad=True)\n",
    "        self.act = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = F.linear(x, weight=self.W, bias=self.b)\n",
    "        z = self.act(z * F.softplus(self.beta))\n",
    "        z = F.linear(z, weight=self.W.T)\n",
    "        return z\n",
    "\n",
    "class ModularGradNet(nn.Module):\n",
    "    def __init__(self, num_modules, in_dim, embed_dim, activation):\n",
    "        super().__init__()\n",
    "        self.num_modules = num_modules\n",
    "        self.mmgn_modules = nn.ModuleList([Module_ModularGN(in_dim, embed_dim, activation) for _ in range(num_modules)])\n",
    "        self.alpha = nn.Parameter(torch.randn(num_modules), requires_grad=True)\n",
    "        self.bias = nn.Parameter(init_b(in_dim), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = 0\n",
    "        for i in range(self.num_modules):\n",
    "            out += self.alpha[i] * self.mmgn_modules[i](x)\n",
    "        out += self.bias\n",
    "        return out\n",
    "\n",
    "# ----- Utils -----\n",
    "def show_comparison_grid(inputs, outputs, title=''):\n",
    "    fig, axes = plt.subplots(2, len(inputs), figsize=(len(inputs) * 2, 4))\n",
    "    for i in range(len(inputs)):\n",
    "        axes[0, i].imshow(inputs[i].reshape(28, 28).cpu().numpy(), cmap=\"gray\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "        axes[1, i].imshow(outputs[i].reshape(28, 28).cpu().numpy(), cmap=\"gray\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "    axes[0, 0].set_ylabel(\"Input\", fontsize=12)\n",
    "    axes[1, 0].set_ylabel(\"Output\", fontsize=12)\n",
    "    if title:\n",
    "        plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def extract_digits(dataset, digit, n):\n",
    "    return torch.stack([img.view(-1) for img, label in dataset if label == digit][:n])\n",
    "\n",
    "def get_single_digit_samples(dataset, digits):\n",
    "    samples = []\n",
    "    for d in digits:\n",
    "        for img, label in dataset:\n",
    "            if label == d:\n",
    "                samples.append(img.view(-1))\n",
    "                break\n",
    "    return torch.stack(samples)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist_full = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_train, mnist_val = random_split(mnist_full, [50000, 10000])\n",
    "\n",
    "digit_pairs = [(i, (i + 1) % 10) for i in range(10)]\n",
    "samples_per_digit = 2000\n",
    "\n",
    "all_source_images = []\n",
    "all_target_images = []\n",
    "\n",
    "for src, tgt in digit_pairs:\n",
    "    src_imgs = extract_digits(mnist_train, src, samples_per_digit)\n",
    "    tgt_imgs = extract_digits(mnist_train, tgt, samples_per_digit)\n",
    "    all_source_images.append(src_imgs)\n",
    "    all_target_images.append(tgt_imgs)\n",
    "\n",
    "X_all = torch.cat(all_source_images, dim=0)\n",
    "Y_all = torch.cat(all_target_images, dim=0)\n",
    "\n",
    "train_dataset = TensorDataset(X_all, Y_all)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# ----- Initialisation -----\n",
    "generator = ModularGradNet(num_modules=20, in_dim=28*28, embed_dim=256, activation=nn.Tanh)\n",
    "optimizer = optim.Adam(generator.parameters(), lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "loss_fn = SamplesLoss(\"sinkhorn\", p=2, blur=0.03)\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    generator.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        g_x = generator(x_batch)\n",
    "        loss = loss_fn(g_x, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.6f}\")\n",
    "\n",
    "    if (epoch + 1) % 20 == 0 or epoch == num_epochs - 1:\n",
    "        with torch.no_grad():\n",
    "            test_inputs = torch.cat([imgs[:1] for imgs in all_source_images], dim=0)\n",
    "            test_outputs = generator(test_inputs)\n",
    "            show_comparison_grid(test_inputs, test_outputs, title=f\"Epoch {epoch+1} - Transport 0→1 ... 9→0\")\n",
    "\n",
    "print(\"\\n Test final (données jamais vues) :\")\n",
    "input_digits = list(range(10))\n",
    "val_inputs = get_single_digit_samples(mnist_val, input_digits)\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_outputs = generator(val_inputs)\n",
    "\n",
    "transformations = [f\"{i}→{(i+1)%10}\" for i in range(10)]\n",
    "input_labels = [f\"[{i}]\" for i in range(10)]\n",
    "\n",
    "print(\"  \".join(transformations))\n",
    "print(\"  \".join(input_labels))\n",
    "\n",
    "show_comparison_grid(val_inputs, val_outputs, title=\"Résultat final - Validation (0→1 ... 9→0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Experiment of Digit Generation from a gaussian distribution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from geomloss import SamplesLoss\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "\n",
    "def init_W(embed_dim, in_dim):\n",
    "    return torch.randn(embed_dim, in_dim) * 0.01\n",
    "\n",
    "def init_b(size):\n",
    "    return torch.zeros(size)\n",
    "\n",
    "class Module_ModularGN(nn.Module):\n",
    "    def __init__(self, in_dim, embed_dim, activation):\n",
    "        super().__init__()\n",
    "        self.beta = nn.Parameter(torch.rand(1), requires_grad=True)\n",
    "        self.W = nn.Parameter(init_W(embed_dim, in_dim), requires_grad=True)\n",
    "        self.b = nn.Parameter(init_b(embed_dim), requires_grad=True)\n",
    "        self.act = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = F.linear(x, weight=self.W, bias=self.b)\n",
    "        z = self.act(z * F.softplus(self.beta))\n",
    "        z = F.linear(z, weight=self.W.T)\n",
    "        return z\n",
    "\n",
    "class ModularGradNet(nn.Module):\n",
    "    def __init__(self, num_modules, in_dim, embed_dim, activation):\n",
    "        super().__init__()\n",
    "        self.num_modules = num_modules\n",
    "        self.mmgn_modules = nn.ModuleList([Module_ModularGN(in_dim, embed_dim, activation) for _ in range(num_modules)])\n",
    "        self.alpha = nn.Parameter(torch.randn(num_modules), requires_grad=True)\n",
    "        self.bias = nn.Parameter(init_b(in_dim), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = 0\n",
    "        for i in range(self.num_modules):\n",
    "            out += self.alpha[i] * self.mmgn_modules[i](x)\n",
    "        out += self.bias\n",
    "        return out\n",
    "\n",
    "def show_grid(images, title=''):\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(len(images) * 2, 2))\n",
    "    for i in range(len(images)):\n",
    "        axes[i].imshow(images[i].reshape(28, 28).cpu().numpy(), cmap=\"gray\")\n",
    "        axes[i].axis(\"off\")\n",
    "    if title:\n",
    "        plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist_full = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_train, mnist_val = random_split(mnist_full, [50000, 10000])\n",
    "\n",
    "num_train_samples = 10000\n",
    "num_val_samples = 2000\n",
    "input_dim = 28 * 28\n",
    "\n",
    "train_noise = torch.randn(num_train_samples, input_dim)\n",
    "train_targets = torch.stack([img.view(-1) for img, _ in list(mnist_train)[:num_train_samples]])\n",
    "\n",
    "val_noise = torch.randn(num_val_samples, input_dim)\n",
    "val_targets = torch.stack([img.view(-1) for img, _ in list(mnist_val)[:num_val_samples]])\n",
    "\n",
    "train_dataset = TensorDataset(train_noise, train_targets)\n",
    "val_dataset = TensorDataset(val_noise, val_targets)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# ----- Initialisation -----\n",
    "generator = ModularGradNet(num_modules=50, in_dim=input_dim, embed_dim=512, activation=nn.Tanh)\n",
    "optimizer = optim.Adam(generator.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "loss_fn = SamplesLoss(\"sinkhorn\", p=2, blur=0.03)\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    generator.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        g_x = generator(x_batch)\n",
    "        loss = loss_fn(g_x, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "\n",
    "    generator.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            g_val = generator(x_val)\n",
    "            val_loss = loss_fn(g_val, y_val)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {total_loss/len(train_loader):.6f} | Val Loss: {total_val_loss/len(val_loader):.6f}\")\n",
    "\n",
    "    if (epoch + 1) % 20 == 0 or epoch == num_epochs - 1:\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(10, input_dim)\n",
    "            samples = generator(z)\n",
    "            show_grid(samples, title=f\"Generated digits at epoch {epoch+1}\")\n",
    "\n",
    "print(\"\\n Génération finale depuis du bruit (validation)\")\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(10, input_dim)\n",
    "    samples = generator(z)\n",
    "    show_grid(samples, title=\"Final generated digits from noise\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CIFAR colorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from geomloss import SamplesLoss\n",
    "\n",
    "def init_W(embed_dim, in_dim):\n",
    "    k = np.sqrt(1 / in_dim)\n",
    "    return 2 * k * torch.rand(embed_dim, in_dim) - k\n",
    "\n",
    "def init_b(embed_dim, in_dim):\n",
    "    k = np.sqrt(1 / in_dim)\n",
    "    return 2 * k * torch.rand(embed_dim,) - k\n",
    "\n",
    "class CascadeGradNet(nn.Module):\n",
    "    def __init__(self, num_layers, in_dim, embed_dim, activation):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.nonlinearity = nn.ModuleList([activation() for _ in range(num_layers)])\n",
    "        self.W = nn.Parameter(init_W(embed_dim, in_dim), requires_grad=True)\n",
    "        self.bias = nn.ParameterList([nn.Parameter(init_b(embed_dim, embed_dim), requires_grad=True) for _ in range(num_layers+1)])\n",
    "        self.bias[0] = nn.Parameter(init_b(embed_dim, in_dim), requires_grad=True)\n",
    "        self.bias[-1] = nn.Parameter(init_b(in_dim, embed_dim), requires_grad=True)\n",
    "        self.beta = nn.ParameterList([nn.Parameter(torch.rand(embed_dim)-0.5, requires_grad=True) for _ in range(num_layers)])\n",
    "        self.alpha = nn.ParameterList([nn.Parameter(torch.rand(embed_dim)-0.5, requires_grad=True) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.beta[0].view(1,-1) * F.linear(x, self.W, self.bias[0])\n",
    "        for i in range(self.num_layers - 1):\n",
    "            skip = self.beta[i+1].view(1,-1) * F.linear(x, self.W, self.bias[i+1])\n",
    "            z = skip + self.alpha[i].view(1,-1) * self.nonlinearity[i](z)\n",
    "        z = self.alpha[-1].view(1,-1) * self.nonlinearity[-1](z)\n",
    "        z = F.linear(z, self.W.T, self.bias[-1])\n",
    "        return z\n",
    "\n",
    "class GrayscaleToColorDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.to_grayscale = transforms.Grayscale(num_output_channels=1)\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        color_img, _ = self.dataset[idx]\n",
    "        gray_img = self.to_grayscale(color_img)\n",
    "        gray_img = gray_img.expand(3, -1, -1).contiguous()\n",
    "        return gray_img.reshape(-1), color_img.contiguous().reshape(-1)\n",
    "\n",
    "data_root = \"./data_cifar10\"\n",
    "image_size = 32\n",
    "subset_size = 5000\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "full_dataset = datasets.CIFAR10(root=data_root, train=True, download=True, transform=transform)\n",
    "indices = np.random.choice(len(full_dataset), subset_size, replace=False)\n",
    "dataset = Subset(full_dataset, indices)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_subset, val_subset = random_split(dataset, [train_size, val_size])\n",
    "train_dataset = GrayscaleToColorDataset(train_subset)\n",
    "val_dataset = GrayscaleToColorDataset(val_subset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "input_dim = image_size * image_size * 3\n",
    "generator = CascadeGradNet(num_layers=24, in_dim=input_dim, embed_dim=512, activation=nn.Tanh)\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "loss_fn = SamplesLoss(\"sinkhorn\", p=2, blur=0.03)\n",
    "\n",
    "num_epochs = 350\n",
    "best_val_loss = float(\"inf\")\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "model_path = \"best_generator.pt\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    generator.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = generator(x_batch)\n",
    "        loss = loss_fn(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    generator.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            val_output = generator(x_val)\n",
    "            val_loss = loss_fn(val_output, y_val)\n",
    "            total_val_loss += val_loss.item()\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(generator.state_dict(), model_path)\n",
    "        print(f\"Nouveau meilleur modèle sauvegardé à epoch {epoch+1} (val_loss = {best_val_loss:.6f})\")\n",
    "\n",
    "    if (epoch + 1) % 20 == 0 or epoch == num_epochs:\n",
    "        generator.eval()\n",
    "        with torch.no_grad():\n",
    "            val_indices = np.random.choice(len(val_dataset), size=8, replace=False)\n",
    "            samples = [val_dataset[i] for i in val_indices]\n",
    "            sample_input = torch.stack([s[0] for s in samples])\n",
    "            sample_target = torch.stack([s[1] for s in samples])\n",
    "            sample_output = generator(sample_input)\n",
    "\n",
    "            fig, axes = plt.subplots(3, 8, figsize=(16, 6))\n",
    "            for i in range(8):\n",
    "                img_input = sample_input[i].view(3, image_size, image_size).permute(1, 2, 0).cpu().numpy()\n",
    "                img_output = sample_output[i].view(3, image_size, image_size).permute(1, 2, 0).cpu().numpy() * 0.5 + 0.5\n",
    "                img_target = sample_target[i].view(3, image_size, image_size).permute(1, 2, 0).cpu().numpy() * 0.5 + 0.5\n",
    "\n",
    "                axes[0, i].imshow(img_input, cmap=\"gray\")\n",
    "                axes[1, i].imshow(np.clip(img_output, 0, 1))\n",
    "                axes[2, i].imshow(np.clip(img_target, 0, 1))\n",
    "\n",
    "                for row in range(3):\n",
    "                    axes[row, i].axis(\"off\")\n",
    "\n",
    "            axes[0, 0].set_ylabel(\"Noir & Blanc\", fontsize=12)\n",
    "            axes[1, 0].set_ylabel(\"Généré\", fontsize=12)\n",
    "            axes[2, 0].set_ylabel(\"Réel\", fontsize=12)\n",
    "            plt.suptitle(f\"Epoch {epoch+1} – Résultats aléatoires sur Validation\", fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Épochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Courbes de perte (Train vs Validation)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Colorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from geomloss import SamplesLoss\n",
    "\n",
    "def init_W(embed_dim, in_dim):\n",
    "    k = np.sqrt(1 / in_dim)\n",
    "    return 2 * k * torch.rand(embed_dim, in_dim) - k\n",
    "\n",
    "def init_b(embed_dim, in_dim):\n",
    "    k = np.sqrt(1 / in_dim)\n",
    "    return 2 * k * torch.rand(embed_dim,) - k\n",
    "\n",
    "class CascadeGradNet(nn.Module):\n",
    "    def __init__(self, num_layers, in_dim, embed_dim, activation=nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.nonlinearity = nn.ModuleList([activation() for _ in range(num_layers)])\n",
    "        self.W = nn.Parameter(init_W(embed_dim, in_dim), requires_grad=True)\n",
    "        self.bias = nn.ParameterList([nn.Parameter(init_b(embed_dim, embed_dim)) for _ in range(num_layers + 1)])\n",
    "        self.bias[0] = nn.Parameter(init_b(embed_dim, in_dim))\n",
    "        self.bias[-1] = nn.Parameter(init_b(in_dim, embed_dim))\n",
    "        self.beta = nn.ParameterList([nn.Parameter(torch.rand(embed_dim) - 0.5) for _ in range(num_layers)])\n",
    "        self.alpha = nn.ParameterList([nn.Parameter(torch.rand(embed_dim) - 0.5) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.beta[0].view(1, -1) * F.linear(x, self.W, self.bias[0])\n",
    "        for i in range(self.num_layers - 1):\n",
    "            skip = self.beta[i + 1].view(1, -1) * F.linear(x, self.W, self.bias[i + 1])\n",
    "            z = skip + self.alpha[i].view(1, -1) * self.nonlinearity[i](z)\n",
    "        z = self.alpha[-1].view(1, -1) * self.nonlinearity[-1](z)\n",
    "        z = F.linear(z, self.W.T, self.bias[-1])\n",
    "        return z\n",
    "\n",
    "def sample_batch(x, batch_size):\n",
    "    idx = torch.randperm(x.shape[0])[:batch_size]\n",
    "    return x[idx]\n",
    "\n",
    "def train_transport_sinkhorn(model, x_input, x_target, size, epochs=1000, lr=1e-3, batch_size=2048, device='cpu', display_every=100):\n",
    "    model.to(device)\n",
    "    x_input = x_input.to(device)\n",
    "    x_target = x_target.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    sinkhorn_loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.01)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_input_batch = sample_batch(x_input, batch_size)\n",
    "        x_target_batch = sample_batch(x_target, batch_size)\n",
    "\n",
    "        x_output = model(x_input_batch).clamp(0, 1)\n",
    "        loss = sinkhorn_loss(x_output, x_target_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"[{epoch}/{epochs}] Sinkhorn Loss: {loss.item():.6f}\")\n",
    "\n",
    "        if epoch % display_every == 0 or epoch == epochs - 1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                stylized = model(x_input).clamp(0, 1)\n",
    "            stylized_image = stylized.reshape(size[1], size[0], 3).cpu().numpy()\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.title(f\"Stylized Image - Epoch {epoch}\")\n",
    "            plt.imshow(stylized_image)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "def image_to_colors(img_path):\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    transform = transforms.ToTensor()\n",
    "    tensor = transform(image).permute(1, 2, 0)\n",
    "    pixels = tensor.reshape(-1, 3)\n",
    "    return pixels, image.size, tensor\n",
    "\n",
    "def fit_gaussian(x):\n",
    "    mu = x.mean(dim=0)\n",
    "    cov = torch.from_numpy(np.cov(x.T.numpy())).float()\n",
    "    return mu, cov\n",
    "\n",
    "def sample_from_gaussian(mu, cov, n_samples):\n",
    "    dist = torch.distributions.MultivariateNormal(mu, covariance_matrix=cov)\n",
    "    return dist.sample((n_samples,))\n",
    "\n",
    "def apply_transport(model, color_tensor, size):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        stylized = model(color_tensor).clamp(0, 1)\n",
    "    stylized_image = stylized.reshape(size[1], size[0], 3).cpu().numpy()\n",
    "    return stylized_image\n",
    "\n",
    "def style_transfer_pipeline_sinkhorn(image_source_path, image_style_path, save_path=\"stylized_output.jpg\", epochs=1000, display_every=100, batch_size=2048):\n",
    "    print(\"Chargement des images...\")\n",
    "    x_input, size, _ = image_to_colors(image_source_path)\n",
    "    x_style, _, _ = image_to_colors(image_style_path)\n",
    "\n",
    "    print(\"Estimation de la gaussienne de style...\")\n",
    "    mu_s, cov_s = fit_gaussian(x_style)\n",
    "    x_target = sample_from_gaussian(mu_s, cov_s, x_input.shape[0])\n",
    "\n",
    "    print(\"Initialisation du modèle...\")\n",
    "    model = CascadeGradNet(num_layers=3, in_dim=3, embed_dim=128)\n",
    "\n",
    "    print(\"Entraînement avec Sinkhorn (geomloss)...\")\n",
    "    train_transport_sinkhorn(model, x_input, x_target, size,\n",
    "                             epochs=epochs, lr=1e-3,\n",
    "                             batch_size=batch_size,\n",
    "                             display_every=display_every)\n",
    "\n",
    "    print(\"Application finale du style...\")\n",
    "    final_image = apply_transport(model, x_input, size)\n",
    "\n",
    "    final_pil = Image.fromarray((final_image * 255).astype(np.uint8))\n",
    "    final_pil.save(save_path)\n",
    "    print(f\"Image stylisée sauvegardée dans : {save_path}\")\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.title(\"Résultat final\")\n",
    "    plt.imshow(final_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "style_transfer_pipeline_sinkhorn(\"data/marseille.jpeg\", \"data/soleil2.jpg\", save_path=\"stylized_output_sinkhorn.jpg\", epochs=500, batch_size=2048, display_every=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
